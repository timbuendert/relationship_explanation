# Dataset Construction

This folder contains the code associated with the construction of the final data corpus which in turn is based on the [**S2ORC** corpus](https://github.com/allenai/s2orc). First, `0_filter_principal_paper/` is used to retrieve the possible principal documents by filtering for papers belonging to the computer science / NLP domain. Based on this set of papers, their related work sections are extracted (`1_setup/`) and passed to the [CORWA pipeline](https://github.com/jacklxc/CORWA) (`2_CORWA/`). This is used for tagging those sections regarding their discourse types, amongst others. To do so, the pre-trained tagger model `joint_tagger_train_scibert_final.model` from the [Google Drive folder](https://drive.google.com/drive/folders/1uGxfWfnK_PtNfKEfuc2EbCuEQpZpjnQJ?usp=sharing) needs to be added to `2_CORWA/`. Using `3_process_CORWA/`, these tagged results are then processed to the correct format for the purposes of this work. Also, `0_filter_cited_paper/` is employed to retrieve the paper information of the cited papers in the citations from the **S2ORC** corpus. Finally, the scripts `4_*` are used to add additional information to the obtained samples and combine them into one dataset.
